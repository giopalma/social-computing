{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Secondo progetto di Social Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# importaimo il file .csv usando la libreria Pandas\n",
    "df = pd.read_csv(\"group_5-Palma-Sacchet-Sagliocca.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load utils.py\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "def serealize_json(folder, filename, data):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder,exist_ok=True)\n",
    "    with open(f\"{folder}/{filename}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data,f,ensure_ascii=False,indent=4)\n",
    "        f.close()\n",
    "    print(f\"Data serialized to path: {folder}/{filename}.json\")\n",
    "\n",
    "def read_json(path):\n",
    "    try:\n",
    "        if os.path.exists(path):\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "                data = json.load(file)\n",
    "            return data\n",
    "    except ValueError:\n",
    "        print(\"Path not found, check the correctness of the path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funziona che permette di crere un elemento di un HIT (document)\n",
    "def document_factory(row,human:bool):\n",
    "    document = {\n",
    "        'id': f'{row['id']}',\n",
    "        'statement': row['statement'],\n",
    "        'explanation': row['explanation_human'] if human else row['explanation_model'],\n",
    "        'label': row['label']\n",
    "    }\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from nanoid import generate\n",
    "# Alfabeto utilizzato da nanodi per generare gli ID dei HIT\n",
    "alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "\n",
    "# Funzione per generare un HIT\n",
    "def hit_factory(index:int):\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    # L'obiettivo è selezionare d'apprima una coppia di righe tra le tre, queste avranno le spiegazioni generate\n",
    "    model_df = df.sample(2)\n",
    "    # E successivamente selezionare un altra riga sempre tra le tre, ques'ultima avrà la spiegazione umana\n",
    "    human_df = df.sample()\n",
    "\n",
    "    # Aggiungo i due elementi con explanation_model all'HIT\n",
    "    for _, row in model_df.iterrows():\n",
    "        document = document_factory(row,False)\n",
    "        documents.append(document)\n",
    "    # Aggiungo l'elemento con explanation_human all'HIT\n",
    "    for _, row in human_df.iterrows():\n",
    "        document = document_factory(row,True)\n",
    "        documents.append(document)\n",
    "\n",
    "    # Mescolo casualmente gli elementi dell'HIT\n",
    "    random.shuffle(documents)\n",
    "\n",
    "    # Creo l'HIT\n",
    "    hit = {\n",
    "        'unit_id': f'unit_{index}',\n",
    "        'token_input': generate(alphabet,size=11), # Genera ID di 11 caratteri\n",
    "        'token_output': generate(alphabet,size=11), # Genera ID di 11 caratteri\n",
    "        'documents_number': len(documents),\n",
    "        'documents': documents\n",
    "    }\n",
    "    \n",
    "    return hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data serialized to path: ./hits.json\n"
     ]
    }
   ],
   "source": [
    "# Inizializzo l'array dove mettero gli HITs\n",
    "hits = []\n",
    "\n",
    "# Genero i 12 HITs\n",
    "for i in range(12):\n",
    "    hit = hit_factory(i)\n",
    "    hits.append(hit)\n",
    "\n",
    "serealize_json(\".\",\"hits\",hits)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisi dei dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import statistics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punto 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentuale media di testo annotato: 33.05%\n"
     ]
    }
   ],
   "source": [
    "# Carico il file csv da dove ricavo i dati\n",
    "dataframe = pd.read_csv(\"csv/workers_notes.csv\")\n",
    "\n",
    "# Filtro solo le colonne che mi interessano\n",
    "note_df = dataframe[['note_text_raw', 'note_text_left', 'note_text_right']]\n",
    "# Converto le frasi in numeri (contando il numero di parole). Utilizzo regex per non considerare la punteggiatura\n",
    "note_df_num = note_df.applymap(lambda x: len(re.findall(r'\\w+', str(x))))\n",
    "# Aggiungo una nuova colonna con il totale delle parole\n",
    "note_df_num['note_text_total'] = note_df_num['note_text_raw'] + note_df_num['note_text_left'] + note_df_num['note_text_right']\n",
    "# Aggiungo una nuova colonna con il valore percentuale\n",
    "note_df_num['percentual'] = (note_df_num['note_text_raw'] / note_df_num['note_text_total']) * 100\n",
    "# Calcolo la percentuale media\n",
    "mean = statistics.mean(list(note_df_num['note_text_total']))\n",
    "# Mostro il risultato\n",
    "print(f\"Percentuale media di testo annotato: {round(mean,2)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b3c36198a59ad4403c7a551e6916c61a78e0010e1ee5e0850198f49740cf93cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
